# Security
## User based

[IAM] Policies, you can tell which API calls should be allowed for an user.
### Resource based
**Bucket Policies**: bucket wide rules, allow for crossaccount:
**JSON based policy**
- Resources: buckets and objects
- Effect: Allow/Deny
- Actions: Set of PAI to allow or deny: example: s3:GetObject

We can use the Bucket policy to gran public access to the bucket, force objects to be encrypted at upload or grant access to another account.

To give a EC2 instance access to the S3 bucket, we use [[EC2]] instance roles to give IAM permissions.

Cross account access: in the bucket policy, we authorize the cross acount.

Then, we have the Block Public access section, that have priority over everything, prevents errors on policies. It can be set on the account level.

Example of S3 policy that makes everything public:
```
{
  "Id": "Policy1696681279453",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "Stmt1696681278339",
      "Action": [
        "s3:GetObject"
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::really-tired/*",
      "Principal": "*"
    }
  ]
}
```
**Object Access control List**: finer granularity, can be disabled
**Bucket ACL**: less common, can be disabled

An IAM principal can access a S3 object if the user IAM permissions allow it OR the resource policy allows it AND there is no explicit DENY

### Encryption

**SSE-S3**: enabled by deafult:
	No access to the key, [[AES]]-256
	Must set a header over https, called x-amz-server-side-encryption.
**SSE-KMS** using [[KMS]] to manage the encryption keys:
	User control over these keys, keys can be audited using [[CloudTrail]]
	Set https header value to aws:kms
	After uploading files like this, you need also access to the kms keys to be able to read the objects. Each read will require the Decrypt KMS API and you might get up to 30000 calls per second, so if you have a very high throughput, this is not a great strategy. Higher values need to be requested through a ticket.
**SSE-C** client provided key:
	AWS does not store this key. HTTPS must be used because you are sending the key there, and the encryption key must be provided in every HTTP request.
**Client side encryption**: 
	You can use Client-side encryption library to simplify the process. The decryption also happens in the client. 


#### Encryption in transit
SSL/TLS: recommended to use it as well. Mandatory for SSE-C.
Most clients use https endpoints by default.
It can be forced with a Bucket Policy, set a condition of the bool type called aws:SecureTransport, using a deny statement.

You can also force an specific type of encryption, by using a Bucket Policy, for example:

```
Condition:{
	StringNotEquals:{
		s3:x-amz-server-side-encryption: aws:kms
	}
}
```

## VPC Endpoints:

By default, when a S3 bucket is accessed from a Public EC2 instance, it is accessed through a Internet Gateway, and from there it goes to the S3 bucket over the public www.

If a EC2 instance is set inside a VPC, it goes through a VPC Endpoint Gateway. A policy can be set to only allow operations through AWS:SourceVpc, or even AWS:SourceVpce to specify a unique VPC.

## Thinking about costs

When getting content of a bucket, it is important to remember that the list operation charges the same if it returns 1, 10 or a 1000 files. The limit is 1000, so we need to paginate sometimes. But still, it is preferable to get as many files as possible in the listing and then filter them out by code instead of trying to do multiple smaller list by some query conditions.
For paginating, we use the response field isTruncated to check if there is need for pagination. If there is such a need, we use the response field NextContinuationToken, that will show the next key. This next key of the next page is used on the request, in the start_after field.

## CW/SAM templating

```
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    Properties:
      BucketName: DOC-EXAMPLE-BUCKET
```
DeletionPolicy is very useful for [[CW]] so that the S3 Bucket is kept after deleting the stack.
`
## Command line

- List objects of a bucket
`aws s3api list-objects --bucket eth-analysis-databucket-1h76jq2x0s25g`

- List only keys under a given folder:
`aws s3api list-objects-v2 --bucket eth-analysis-databucket-1h76jq2x0s25g --prefix gas_averages --query "Contents[].Key"`
